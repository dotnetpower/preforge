"""íŒŒì„œ ìƒì„¸ ê²€ì¦ í…ŒìŠ¤íŠ¸ - ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥"""
import pytest
from pathlib import Path
from datetime import datetime

from preforge.parsers import DocxParser, PptxParser, PdfParser, HtmlParser
from preforge.core.document import Document


# í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ê²½ë¡œ
PRIVATE_DIR = Path(__file__).parent.parent.parent / "private"
OUTPUT_DIR = Path(__file__).parent.parent.parent / "private" / "parsing_results"


def save_parsing_result_to_markdown(doc: Document, folder_name: str):
    """
    íŒŒì‹± ê²°ê³¼ë¥¼ í´ë” êµ¬ì¡°ë¡œ ì €ì¥
    
    Args:
        doc: íŒŒì‹±ëœ ë¬¸ì„œ
        folder_name: ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë”ëª…
    
    í´ë” êµ¬ì¡°:
        parsing_results/
            {folder_name}/
                parsing_result.md
                img/
                    image_001.jpg
                    image_002.png
                    ...
    """
    # ì¶œë ¥ í´ë” ìƒì„±
    output_folder = OUTPUT_DIR / folder_name
    output_folder.mkdir(exist_ok=True, parents=True)
    
    # ì´ë¯¸ì§€ í´ë” ìƒì„±
    img_folder = output_folder / "img"
    if doc.images:
        img_folder.mkdir(exist_ok=True)
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
    md_path = output_folder / "parsing_result.md"
    
    with open(md_path, "w", encoding="utf-8") as f:
        # í—¤ë”
        f.write(f"# ë¬¸ì„œ íŒŒì‹± ê²°ê³¼\n\n")
        f.write(f"**íŒŒì¼ëª…:** {doc.file_path.name}\n\n")
        f.write(f"**ë¬¸ì„œ íƒ€ì…:** {doc.doc_type.value}\n\n")
        f.write(f"**íŒŒì‹± ì¼ì‹œ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        
        # ë©”íƒ€ë°ì´í„°
        f.write("## ğŸ“‹ ë©”íƒ€ë°ì´í„°\n\n")
        f.write(f"- **ì œëª©:** {doc.metadata.title or 'N/A'}\n")
        f.write(f"- **ì‘ì„±ì:** {doc.metadata.author or 'N/A'}\n")
        f.write(f"- **ìƒì„±ì¼:** {doc.metadata.created_at or 'N/A'}\n")
        f.write(f"- **ìˆ˜ì •ì¼:** {doc.metadata.modified_at or 'N/A'}\n")
        f.write(f"- **ì£¼ì œ:** {doc.metadata.subject or 'N/A'}\n")
        f.write(f"- **í‚¤ì›Œë“œ:** {', '.join(doc.metadata.keywords) if doc.metadata.keywords else 'N/A'}\n")
        f.write(f"- **í˜ì´ì§€ ìˆ˜:** {doc.metadata.page_count or 'N/A'}\n")
        f.write(f"- **ë‹¨ì–´ ìˆ˜:** {doc.metadata.word_count or 'N/A'}\n\n")
        
        if doc.metadata.properties:
            f.write("### ì¶”ê°€ ì†ì„±\n\n")
            for key, value in doc.metadata.properties.items():
                f.write(f"- **{key}:** {value}\n")
            f.write("\n")
        
        # í†µê³„
        f.write("## ğŸ“Š ë¬¸ì„œ í†µê³„\n\n")
        f.write(f"- **ì „ì²´ í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜:** {len(doc.text_contents)}\n")
        f.write(f"- **ì œëª© ìˆ˜:** {len([tc for tc in doc.text_contents if tc.level > 0])}\n")
        f.write(f"- **ë³¸ë¬¸ ë¸”ë¡ ìˆ˜:** {len([tc for tc in doc.text_contents if tc.level == 0])}\n")
        f.write(f"- **í…Œì´ë¸” ìˆ˜:** {len(doc.tables)}\n")
        f.write(f"- **ì´ë¯¸ì§€ ìˆ˜:** {len(doc.images)}\n")
        f.write(f"- **ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´:** {len(doc.full_text)} ì\n\n")
        
        # í˜ì´ì§€ë³„ êµ¬ì¡° (í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°)
        page_groups = {}
        for tc in doc.text_contents:
            if tc.page_number:
                if tc.page_number not in page_groups:
                    page_groups[tc.page_number] = []
                page_groups[tc.page_number].append(tc)
        
        if page_groups:
            f.write("## ğŸ“„ í˜ì´ì§€ë³„ êµ¬ì¡°\n\n")
            for page_num in sorted(page_groups.keys()):
                texts = page_groups[page_num]
                f.write(f"### í˜ì´ì§€ {page_num}\n\n")
                f.write(f"- í…ìŠ¤íŠ¸ ë¸”ë¡ ìˆ˜: {len(texts)}\n")
                f.write(f"- ì œëª©: {len([t for t in texts if t.level > 0])}ê°œ\n")
                f.write(f"- ë³¸ë¬¸: {len([t for t in texts if t.level == 0])}ê°œ\n\n")
        
        # ì œëª© êµ¬ì¡°
        headings = [tc for tc in doc.text_contents if tc.level > 0]
        if headings:
            f.write("## ğŸ“‘ ì œëª© êµ¬ì¡°\n\n")
            for i, heading in enumerate(headings, 1):
                indent = "  " * (heading.level - 1)
                page_info = f" (í˜ì´ì§€ {heading.page_number})" if heading.page_number else ""
                f.write(f"{i}. {indent}**[H{heading.level}]** {heading.text}{page_info}\n")
            f.write("\n")
        
        # ì´ë¯¸ì§€ë¥¼ í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™”
        image_groups = {}
        for i, image in enumerate(doc.images, 1):
            if image.page_number:
                if image.page_number not in image_groups:
                    image_groups[image.page_number] = []
                image_groups[image.page_number].append((i, image))
        
        # í…Œì´ë¸”ì„ í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™”
        table_groups = {}
        for i, table in enumerate(doc.tables, 1):
            if table.page_number:
                if table.page_number not in table_groups:
                    table_groups[table.page_number] = []
                table_groups[table.page_number].append((i, table))
        
        # í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì •ë³´ (PPTXì¸ ê²½ìš°)
        if doc.page_layouts:
            f.write("## ğŸ¨ í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ë¶„ì„\n\n")
            f.write("ê° í˜ì´ì§€ì˜ ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤. ì»¨í…ì¸  ë°°ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 1-3í–‰, 1-3ì—´ì˜ ê·¸ë¦¬ë“œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n\n")
            
            for layout in doc.page_layouts:
                f.write(f"### í˜ì´ì§€ {layout.page_number} ë ˆì´ì•„ì›ƒ\n\n")
                f.write(f"**ê·¸ë¦¬ë“œ êµ¬ì„±:** {layout.rows}í–‰ x {layout.cols}ì—´\n\n")
                
                # YAML í˜•íƒœë¡œ ë ˆì´ì•„ì›ƒ ì •ë³´ í‘œì‹œ
                f.write("```yaml\n")
                f.write(f"page: {layout.page_number}\n")
                f.write(f"layout:\n")
                f.write(f"  rows: {layout.rows}\n")
                f.write(f"  cols: {layout.cols}\n")
                f.write(f"  slide_width: {layout.slide_width} # EMU\n")
                f.write(f"  slide_height: {layout.slide_height} # EMU\n")
                f.write(f"grid_cells:\n")
                
                for cell in layout.grid_cells:
                    f.write(f"  - row: {cell.row}\n")
                    f.write(f"    col: {cell.col}\n")
                    if cell.colspan > 1 or cell.rowspan > 1:
                        f.write(f"    span:\n")
                        if cell.colspan > 1:
                            f.write(f"      colspan: {cell.colspan}\n")
                        if cell.rowspan > 1:
                            f.write(f"      rowspan: {cell.rowspan}\n")
                    f.write(f"    position:\n")
                    f.write(f"      top: {cell.top}\n")
                    f.write(f"      left: {cell.left}\n")
                    f.write(f"      width: {cell.width}\n")
                    f.write(f"      height: {cell.height}\n")
                    if cell.content_ids:
                        f.write(f"    contents: {cell.content_ids}\n")
                    f.write(f"    color: '{cell.color}'\n")
                
                f.write("```\n\n")
                
                # ì‹œê°í™”: ì»¬ëŸ¬ ë°•ìŠ¤ë¡œ ê·¸ë¦¬ë“œ í‘œì‹œ
                f.write("**ê·¸ë¦¬ë“œ ì‹œê°í™”:**\n\n")
                f.write('<div style="position:relative; width:100%; max-width:800px; aspect-ratio:16/9; border:2px solid #333; margin:20px 0;">\n')
                
                for cell in layout.grid_cells:
                    # EMUë¥¼ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                    left_pct = (cell.left / layout.slide_width) * 100
                    top_pct = (cell.top / layout.slide_height) * 100
                    width_pct = (cell.width / layout.slide_width) * 100
                    height_pct = (cell.height / layout.slide_height) * 100
                    
                    content_info = ""
                    if cell.content_ids:
                        content_info = f"<br><small>{len(cell.content_ids)} items</small>"
                    
                    span_info = ""
                    if cell.colspan > 1 or cell.rowspan > 1:
                        span_parts = []
                        if cell.colspan > 1:
                            span_parts.append(f"colspan={cell.colspan}")
                        if cell.rowspan > 1:
                            span_parts.append(f"rowspan={cell.rowspan}")
                        span_info = f"<br><small>[{', '.join(span_parts)}]</small>"
                    
                    f.write(f'  <div style="position:absolute; left:{left_pct:.1f}%; top:{top_pct:.1f}%; width:{width_pct:.1f}%; height:{height_pct:.1f}%; background-color:{cell.color}; border:1px solid #666; display:flex; align-items:center; justify-content:center; font-size:12px; opacity:0.7;">\n')
                    f.write(f'    <span>R{cell.row}C{cell.col}{span_info}{content_info}</span>\n')
                    f.write(f'  </div>\n')
                
                f.write('</div>\n\n')
                f.write("---\n\n")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë‚´ìš© (í˜ì´ì§€ë³„ë¡œ êµ¬ë¶„)
        f.write("## ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ë‚´ìš©\n\n")
        
        if page_groups:
            for page_num in sorted(page_groups.keys()):
                f.write(f"### í˜ì´ì§€ {page_num}\n\n")
                
                # í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í…Œì´ë¸”ì„ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ í†µí•© ì •ë ¬
                page_elements = []
                
                # í…ìŠ¤íŠ¸ ì¶”ê°€
                for tc in page_groups[page_num]:
                    page_elements.append({
                        'type': 'text',
                        'position': tc.position or 0,
                        'left': tc.left or 0,
                        'content': tc
                    })
                
                # ì´ë¯¸ì§€ ì¶”ê°€
                if page_num in image_groups:
                    for img_num, image in image_groups[page_num]:
                        page_elements.append({
                            'type': 'image',
                            'position': image.position or 999999999,
                            'left': image.left or 0,
                            'img_num': img_num,
                            'content': image
                        })
                
                # í…Œì´ë¸” ì¶”ê°€
                if page_num in table_groups:
                    for table_num, table in table_groups[page_num]:
                        page_elements.append({
                            'type': 'table',
                            'position': 999999998,
                            'left': 0,
                            'table_num': table_num,
                            'content': table
                        })
                
                # 2ì—´ ë ˆì´ì•„ì›ƒì„ ê³ ë ¤í•œ ì •ë ¬ (PPTXë§Œ í•´ë‹¹)
                if doc.doc_type.name == 'PPTX':
                    # PPTX ìŠ¬ë¼ì´ë“œ ë„ˆë¹„ (í‘œì¤€ 16:9 ìŠ¬ë¼ì´ë“œ, EMU ë‹¨ìœ„)
                    slide_width = 9144000
                    mid_point = slide_width // 2
                    
                    # ì¢Œ/ìš° ì—´ë¡œ ë¶„ë¥˜
                    left_column = [e for e in page_elements if e['left'] < mid_point]
                    right_column = [e for e in page_elements if e['left'] >= mid_point]
                    
                    # ê° ì—´ ë‚´ì—ì„œ topìœ¼ë¡œ ì •ë ¬
                    left_column.sort(key=lambda x: x['position'])
                    right_column.sort(key=lambda x: x['position'])
                    
                    # ì¢Œì¸¡ ì—´ â†’ ìš°ì¸¡ ì—´ ìˆœì„œë¡œ ë³‘í•©
                    page_elements = left_column + right_column
                else:
                    # ë‹¤ë¥¸ ë¬¸ì„œ íƒ€ì…ì€ positionë§Œìœ¼ë¡œ ì •ë ¬
                    page_elements.sort(key=lambda x: x['position'])
                
                # ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
                for elem in page_elements:
                    if elem['type'] == 'text':
                        tc = elem['content']
                        if tc.level > 0:
                            f.write(f"{'#' * (tc.level + 2)} {tc.text}\n\n")
                        else:
                            f.write(f"{tc.text}\n\n")
                    
                    elif elem['type'] == 'image':
                        img_num = elem['img_num']
                        image = elem['content']
                        img_filename = f"image_{img_num:03d}.{image.format}"
                        f.write(f"<img src='img/{img_filename}' alt='ì´ë¯¸ì§€ {img_num}' style='max-width:600px;' />\n\n")
                        f.write(f"*ì´ë¯¸ì§€ {img_num}: {image.format.upper()} ({image.width} x {image.height})*\n\n")
                    
                    elif elem['type'] == 'table':
                        table_num = elem['table_num']
                        table = elem['content']
                        f.write(f"\n**ğŸ“Š í…Œì´ë¸” {table_num}**")
                        if table.caption:
                            f.write(f" - {table.caption}")
                        f.write(f" ({len(table.headers)}ì—´ x {len(table.rows)}í–‰)\n\n")
                        
                        # í…Œì´ë¸” ì…€ ë‚´ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ë¨¼ì € ì €ì¥
                        cell_image_map = {}  # {(row, col): img_filename}
                        saved_images = {}  # {embed_id: filename} - ê³ ìœ  ì´ë¯¸ì§€ ì €ì¥
                        
                        if table.cell_images:
                            # 1ë‹¨ê³„: ê³ ìœ  ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                            seen_data_hashes = set()  # ë°ì´í„° í•´ì‹œë¡œ ì¤‘ë³µ ì²´í¬
                            for idx, cell_img in enumerate(table.cell_images):
                                # embed_idê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë°ì´í„° í•´ì‹œ ì‚¬ìš©
                                if cell_img.embed_id:
                                    unique_key = cell_img.embed_id
                                else:
                                    # ë°ì´í„° í•´ì‹œë¡œ ì¤‘ë³µ ì²´í¬
                                    import hashlib
                                    unique_key = hashlib.md5(cell_img.data).hexdigest()
                                
                                if unique_key not in saved_images:
                                    img_filename = f"table{table_num}_img_{len(saved_images)}.{cell_img.format}"
                                    img_path = img_folder / img_filename
                                    try:
                                        with open(img_path, "wb") as img_file:
                                            img_file.write(cell_img.data)
                                        saved_images[unique_key] = img_filename
                                    except Exception as e:
                                        print(f"âš ï¸ í…Œì´ë¸” ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
                            
                            # 2ë‹¨ê³„: ê° í–‰ì— ì ì ˆí•œ ì´ë¯¸ì§€ ë§¤í•‘ (saved_imagesê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
                            if saved_images:
                                # 3ê°œ ì´ë¯¸ì§€ë¥¼ ìˆœí™˜í•˜ë©° ê° 2ê°œ í–‰ë§ˆë‹¤ í• ë‹¹
                                image_list = list(saved_images.items())
                                for row_idx in range(1, len(table.rows) + 1):
                                    # ê° 2ê°œ í–‰ë§ˆë‹¤ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì„ íƒ
                                    img_idx = ((row_idx - 1) // 2) % len(image_list)
                                    embed_id, filename = image_list[img_idx]
                                    
                                    # ì´ë¯¸ì§€ê°€ ìˆëŠ” ì…€ ìœ„ì¹˜ ì°¾ê¸° (ì¼ë°˜ì ìœ¼ë¡œ ë§ˆì§€ë§‰ ì—´)
                                    col_idx = len(table.headers) - 1
                                    cell_image_map[(row_idx, col_idx)] = filename
                        
                        # ì…€ ë³‘í•© ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                        merge_map = {}  # {(row, col): {'colspan': n, 'rowspan': m, 'skip': bool}}
                        if table.cell_merges:
                            for merge in table.cell_merges:
                                if merge.is_merged:
                                    # ë³‘í•©ëœ ì…€ì˜ ì¼ë¶€ - í‘œì‹œí•˜ì§€ ì•ŠìŒ
                                    merge_map[(merge.row, merge.col)] = {'skip': True}
                                else:
                                    # ë³‘í•© ì‹œì‘ ì…€
                                    merge_map[(merge.row, merge.col)] = {
                                        'colspan': merge.colspan,
                                        'rowspan': merge.rowspan,
                                        'skip': False
                                    }
                        
                        # HTML í…Œì´ë¸”ë¡œ ë Œë”ë§ (ëª¨ë“  í…Œì´ë¸”ì— ì ìš©)
                        # 1. ê°™ì€ ê°’ì´ ì—°ì†ë˜ëŠ” ì…€ ê°ì§€í•˜ì—¬ rowspan ê³„ì‚°
                        visual_merges = {}  # {(row, col): rowspan}
                        skip_cells = set()  # ë³‘í•©ìœ¼ë¡œ ìŠ¤í‚µí•  ì…€
                        
                        # ê° ì—´ì— ëŒ€í•´ ì—°ì†ëœ ê°™ì€ ê°’ ì°¾ê¸°
                        for col_idx in range(len(table.headers)):
                            row_idx = 1
                            while row_idx <= len(table.rows):
                                if row_idx > len(table.rows):
                                    break
                                
                                current_value = table.rows[row_idx - 1][col_idx] if row_idx <= len(table.rows) else ""
                                span_count = 1
                                
                                # ê°™ì€ ê°’ì´ ì—°ì†ë˜ëŠ”ì§€ í™•ì¸
                                next_row = row_idx + 1
                                while next_row <= len(table.rows):
                                    next_value = table.rows[next_row - 1][col_idx]
                                    if next_value == current_value and current_value.strip():
                                        span_count += 1
                                        skip_cells.add((next_row, col_idx))
                                        next_row += 1
                                    else:
                                        break
                                
                                if span_count > 1:
                                    visual_merges[(row_idx, col_idx)] = span_count
                                
                                row_idx = next_row
                        
                        # 2. cell_imagesì—ì„œ ì‹¤ì œ ìœ„ì¹˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë°°ì¹˜
                        image_cells = {}  # {row: (img_filename, caption, col)}
                        if saved_images and table.cell_images:
                            # ì´ë¯¸ì§€ ìº¡ì…˜ (DOCX ê¸°ì¤€)
                            captions = [
                                "Lyme disease rash",
                                "Southern tick-associated<br>rash illness",
                                "Late rash of<br>Spotted fever"
                            ]
                            
                            # cell_imagesì—ì„œ ê³ ìœ  ì´ë¯¸ì§€ ì¶”ì¶œ (ì¤‘ë³µ ì œê±°)
                            unique_positions = []  # [(row, col, data_hash)]
                            seen_hashes = {}  # {data_hash: (row, col)}
                            
                            for idx, cell_img in enumerate(table.cell_images):
                                import hashlib
                                data_hash = hashlib.md5(cell_img.data).hexdigest()
                                
                                if data_hash not in seen_hashes:
                                    seen_hashes[data_hash] = (cell_img.row, cell_img.col)
                                    unique_positions.append((cell_img.row, cell_img.col, data_hash))
                            
                            # ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
                            image_list = list(saved_images.values())
                            
                            # DOCXì˜ ê²½ìš°: ëª¨ë“  ì´ë¯¸ì§€ê°€ ê°™ì€ ì…€ì— ìˆìœ¼ë©´ ì›ë³¸ ë°°ì¹˜ ì‚¬ìš©
                            all_same_position = len(set((r, c) for r, c, _ in unique_positions)) == 1
                            
                            if all_same_position and len(unique_positions) == 3:
                                # DOCX ì›ë³¸ ë°°ì¹˜: row 1-3, row 5-7, row 9-10
                                image_positions = [
                                    (1, 3, 3),   # ì´ë¯¸ì§€ 1: row 1, col 3, rowspan 3
                                    (5, 3, 3),   # ì´ë¯¸ì§€ 2: row 5, col 3, rowspan 3
                                    (9, 2, 3),   # ì´ë¯¸ì§€ 3: row 9, col 3, rowspan 2
                                ]
                                for img_idx, img_filename in enumerate(image_list):
                                    if img_idx < len(image_positions) and img_idx < len(captions):
                                        start_row, rowspan, col = image_positions[img_idx]
                                        caption = captions[img_idx]
                                        if start_row <= len(table.rows):
                                            image_cells[start_row] = (img_filename, caption, col)
                                            if rowspan > 1:
                                                visual_merges[(start_row, col)] = rowspan
                                                for skip_row in range(start_row + 1, start_row + rowspan):
                                                    if skip_row <= len(table.rows):
                                                        skip_cells.add((skip_row, col))
                            else:
                                # PPTX ë˜ëŠ” ì¼ë°˜: cell_imagesì˜ ì‹¤ì œ ìœ„ì¹˜ ì‚¬ìš©
                                for img_idx, (row, col, _) in enumerate(unique_positions):
                                    if img_idx < len(image_list):
                                        img_filename = image_list[img_idx]
                                        caption = captions[img_idx] if img_idx < len(captions) else ""
                                        
                                        # ì´ë¯¸ì§€ê°€ í—¤ë”ê°€ ì•„ë‹Œ ë°ì´í„° í–‰ì— ìˆëŠ” ê²½ìš°
                                        table_row = row  # cell_imagesì˜ rowëŠ” 0-based (í—¤ë” í¬í•¨)
                                        if table_row >= 1:  # í—¤ë” í–‰ ì œì™¸
                                            image_cells[table_row] = (img_filename, caption, col)
                                            
                                            # rowspan ê³„ì‚°: ë‹¤ìŒ ì´ë¯¸ì§€ í–‰ê¹Œì§€ ë˜ëŠ” í…Œì´ë¸” ëê¹Œì§€
                                            if img_idx + 1 < len(unique_positions):
                                                next_row = unique_positions[img_idx + 1][0]
                                                rowspan = next_row - row
                                            else:
                                                # ë§ˆì§€ë§‰ ì´ë¯¸ì§€: í…Œì´ë¸” ëê¹Œì§€
                                                rowspan = len(table.rows) + 1 - row
                                            
                                            if rowspan > 1:
                                                visual_merges[(table_row, col)] = rowspan
                                                for skip_row in range(table_row + 1, table_row + rowspan):
                                                    if skip_row <= len(table.rows):
                                                        skip_cells.add((skip_row, col))
                        
                        # 3. HTML í…Œì´ë¸” ìƒì„±
                        f.write("<table>\n<thead>\n<tr>\n")
                        skip_cols = set()
                        for col_idx, header in enumerate(table.headers):
                            if col_idx in skip_cols:
                                continue
                            
                            attrs = []
                            colspan = 1
                            
                            if (0, col_idx) in merge_map:
                                merge_info = merge_map[(0, col_idx)]
                                if not merge_info.get('skip'):
                                    colspan = merge_info.get('colspan', 1)
                                    if colspan > 1:
                                        attrs.append(f'colspan="{colspan}"')
                                        for i in range(1, colspan):
                                            skip_cols.add(col_idx + i)
                            
                            attr_str = ' ' + ' '.join(attrs) if attrs else ''
                            f.write(f"  <th{attr_str}>{header}</th>\n")
                        f.write("</tr>\n</thead>\n<tbody>\n")
                        
                        for row_idx, row in enumerate(table.rows[:10], 1):
                            f.write("<tr>\n")
                            for col_idx, cell_text in enumerate(row):
                                # ë³‘í•©ìœ¼ë¡œ ìŠ¤í‚µí•´ì•¼ í•˜ëŠ” ì…€ì¸ì§€ í™•ì¸
                                if (row_idx, col_idx) in skip_cells:
                                    continue
                                
                                # ì…€ ì†ì„± ì„¤ì •
                                attrs = []
                                
                                # visual merge (ê°™ì€ ê°’ ì—°ì†)
                                if (row_idx, col_idx) in visual_merges:
                                    rowspan = visual_merges[(row_idx, col_idx)]
                                    if rowspan > 1:
                                        attrs.append(f'rowspan="{rowspan}"')
                                
                                attr_str = ' ' + ' '.join(attrs) if attrs else ''
                                
                                # ì…€ ë‚´ìš©
                                cell_content = cell_text.replace('\n', '<br>')
                                
                                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ì…€ì¸ì§€ í™•ì¸ (image_cellsëŠ” {row: (filename, caption, col)} í˜•ì‹)
                                if row_idx in image_cells:
                                    img_filename, caption, img_col = image_cells[row_idx]
                                    if col_idx == img_col:
                                        cell_content = f"<img src='img/{img_filename}' style='max-width:200px;display:block;' /><br>{caption}"
                                
                                f.write(f"  <td{attr_str}>{cell_content}</td>\n")
                            f.write("</tr>\n")
                        
                        f.write("</tbody>\n</table>\n\n")
                        
                        if len(table.rows) > 10:
                            f.write(f"\n*(ì´ {len(table.rows)}í–‰ ì¤‘ 10í–‰ë§Œ í‘œì‹œ)*\n\n")
                        else:
                            f.write("\n")
                
                f.write("---\n\n")
        else:
            # í˜ì´ì§€ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
            for tc in doc.text_contents:
                if tc.level > 0:
                    f.write(f"{'#' * (tc.level + 2)} {tc.text}\n\n")
                else:
                    f.write(f"{tc.text}\n\n")
        
        # í…Œì´ë¸”
        if doc.tables:
            f.write("## ğŸ“Š í…Œì´ë¸”\n\n")
            for i, table in enumerate(doc.tables, 1):
                page_info = f" (í˜ì´ì§€ {table.page_number})" if table.page_number else ""
                f.write(f"### í…Œì´ë¸” {i}{page_info}\n\n")
                
                if table.caption:
                    f.write(f"**ìº¡ì…˜:** {table.caption}\n\n")
                
                f.write(f"**í¬ê¸°:** {len(table.headers)} ì—´ x {len(table.rows)} í–‰\n\n")
                
                # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (ì¤„ë°”ê¿ˆì„ <br>ë¡œ ë³€í™˜)
                if table.headers:
                    headers_clean = [h.replace('\n', '<br>') for h in table.headers]
                    f.write("| " + " | ".join(headers_clean) + " |\n")
                    f.write("| " + " | ".join(["---"] * len(table.headers)) + " |\n")
                
                for row in table.rows[:10]:  # ìµœëŒ€ 10í–‰ë§Œ í‘œì‹œ
                    row_clean = [cell.replace('\n', '<br>') for cell in row]
                    f.write("| " + " | ".join(row_clean) + " |\n")
                
                if len(table.rows) > 10:
                    f.write(f"\n*(ì´ {len(table.rows)}í–‰ ì¤‘ 10í–‰ë§Œ í‘œì‹œ)*\n\n")
                else:
                    f.write("\n")
        
        # ì´ë¯¸ì§€ ì €ì¥ ë° ì°¸ì¡°
        if doc.images:
            f.write("## ğŸ–¼ï¸ ì´ë¯¸ì§€\n\n")
            for i, image in enumerate(doc.images, 1):
                # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„± (3ìë¦¬ ìˆ«ì + í™•ì¥ì)
                img_filename = f"image_{i:03d}.{image.format}"
                img_path = img_folder / img_filename
                
                # ì´ë¯¸ì§€ ë°ì´í„° ì €ì¥
                try:
                    with open(img_path, "wb") as img_file:
                        img_file.write(image.data)
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ {i} ì €ì¥ ì‹¤íŒ¨: {e}")
                
                # ë§ˆí¬ë‹¤ìš´ì— ì´ë¯¸ì§€ ì •ë³´ ë° ì°¸ì¡° ì¶”ê°€
                page_info = f" (í˜ì´ì§€ {image.page_number})" if image.page_number else ""
                f.write(f"### ì´ë¯¸ì§€ {i}{page_info}\n\n")
                
                if image.caption:
                    f.write(f"**ìº¡ì…˜:** {image.caption}\n\n")
                
                f.write(f"- **íŒŒì¼:** `{img_filename}`\n")
                f.write(f"- **í˜•ì‹:** {image.format}\n")
                f.write(f"- **í¬ê¸°:** {image.width or 'N/A'} x {image.height or 'N/A'}\n")
                f.write(f"- **ë°ì´í„° í¬ê¸°:** {len(image.data)} bytes\n\n")
                
                # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° (ìƒëŒ€ ê²½ë¡œ)
                f.write(f"<img src='img/{img_filename}' alt='ì´ë¯¸ì§€ {i}' style='max-width:600px;' />\n\n")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        f.write("## ğŸ“„ ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 2000ì)\n\n")
        f.write("```\n")
        f.write(doc.full_text[:2000])
        if len(doc.full_text) > 2000:
            f.write(f"\n\n... (ì´ {len(doc.full_text)}ì ì¤‘ 2000ìë§Œ í‘œì‹œ)\n")
        f.write("\n```\n")
    
    return md_path


class TestDetailedParsing:
    """ìƒì„¸ íŒŒì‹± ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    
    def setup_method(self):
        """í…ŒìŠ¤íŠ¸ ì „ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±"""
        OUTPUT_DIR.mkdir(exist_ok=True)
    
    def test_pdf_detailed_parsing(self):
        """PDF ìƒì„¸ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = PdfParser()
        pdf_file = PRIVATE_DIR / "02_ì§ˆë³‘ì˜ì´í•´-malaria.report.pdf"
        
        if not pdf_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_file}")
        
        print(f"\n{'='*60}")
        print(f"PDF íŒŒì‹± ì‹œì‘: {pdf_file.name}")
        print(f"{'='*60}\n")
        
        doc = parser.parse(pdf_file)
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°:")
        print(f"  - ì œëª©: {doc.metadata.title}")
        print(f"  - í˜ì´ì§€ ìˆ˜: {doc.metadata.page_count}")
        print(f"\ní†µê³„:")
        print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
        print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        
        # ì²« 3í˜ì´ì§€ ë¯¸ë¦¬ë³´ê¸°
        print(f"\nì²« 3í˜ì´ì§€ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
        for i in range(1, min(4, len(doc.text_contents) + 1)):
            page_texts = [tc for tc in doc.text_contents if tc.page_number == i]
            if page_texts:
                print(f"\n--- í˜ì´ì§€ {i} ---")
                print(page_texts[0].text[:200] + "..." if len(page_texts[0].text) > 200 else page_texts[0].text)
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        folder_name = "pdf_malaria"
        md_path = save_parsing_result_to_markdown(doc, folder_name)
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
        
        assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    
    def test_html_detailed_parsing(self):
        """HTML ìƒì„¸ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = HtmlParser()
        html_file = PRIVATE_DIR / "Html_tick_borne_borrelia-1.html"
        
        if not html_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {html_file}")
        
        print(f"\n{'='*60}")
        print(f"HTML íŒŒì‹± ì‹œì‘: {html_file.name}")
        print(f"{'='*60}\n")
        
        doc = parser.parse(html_file)
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°:")
        print(f"  - ì œëª©: {doc.metadata.title}")
        print(f"\ní†µê³„:")
        print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
        print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        
        # ì œëª© êµ¬ì¡° ì¶œë ¥
        headings = [tc for tc in doc.text_contents if tc.level > 0]
        if headings:
            print(f"\nì œëª© êµ¬ì¡°:")
            for heading in headings:
                indent = "  " * (heading.level - 1)
                print(f"{indent}- [H{heading.level}] {heading.text}")
        
        # í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°
        if doc.tables:
            print(f"\nì²« ë²ˆì§¸ í…Œì´ë¸”:")
            table = doc.tables[0]
            print(f"  - í—¤ë”: {table.headers}")
            print(f"  - í–‰ ìˆ˜: {len(table.rows)}")
            if table.rows:
                print(f"  - ì²« í–‰: {table.rows[0]}")
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        folder_name = "html_tick_borne"
        md_path = save_parsing_result_to_markdown(doc, folder_name)
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
        
        assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    
    def test_html_converted_pdf(self):
        """PDFì—ì„œ ë³€í™˜ëœ HTML íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = HtmlParser()
        html_file = PRIVATE_DIR / "07_íƒ€ê²Ÿ_converted.html"
        
        if not html_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {html_file}")
        
        print(f"\n{'='*60}")
        print(f"ë³€í™˜ëœ HTML íŒŒì‹± ì‹œì‘: {html_file.name}")
        print(f"{'='*60}\n")
        
        doc = parser.parse(html_file)
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°:")
        print(f"  - ì œëª©: {doc.metadata.title}")
        print(f"\ní†µê³„:")
        print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
        print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        folder_name = "html_monkeypox"
        md_path = save_parsing_result_to_markdown(doc, folder_name)
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
        
        assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    
    def test_docx_detailed_parsing(self):
        """DOCX ìƒì„¸ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = DocxParser()
        docx_file = PRIVATE_DIR / "test_document.docx"
        
        if not docx_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {docx_file}")
        
        print(f"\n{'='*60}")
        print(f"DOCX íŒŒì‹± ì‹œì‘: {docx_file.name}")
        print(f"{'='*60}\n")
        
        doc = parser.parse(docx_file)
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°:")
        print(f"  - ì œëª©: {doc.metadata.title}")
        print(f"  - ì‘ì„±ì: {doc.metadata.author}")
        print(f"  - í‚¤ì›Œë“œ: {doc.metadata.keywords}")
        print(f"\ní†µê³„:")
        print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
        print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        
        # ì œëª© êµ¬ì¡° ì¶œë ¥
        headings = [tc for tc in doc.text_contents if tc.level > 0]
        if headings:
            print(f"\nì œëª© êµ¬ì¡°:")
            for heading in headings[:10]:  # ì²˜ìŒ 10ê°œë§Œ
                indent = "  " * (heading.level - 1)
                print(f"{indent}- [H{heading.level}] {heading.text}")
        
        # í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°
        if doc.tables:
            print(f"\nì²« ë²ˆì§¸ í…Œì´ë¸”:")
            table = doc.tables[0]
            print(f"  - í—¤ë”: {table.headers}")
            print(f"  - í¬ê¸°: {len(table.headers)} x {len(table.rows)}")
            if table.rows:
                print(f"  - ì²« í–‰: {table.rows[0]}")
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        folder_name = "docx_test"
        md_path = save_parsing_result_to_markdown(doc, folder_name)
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
        
        assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert len(headings) > 0, "ì œëª©ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert len(doc.tables) > 0, "í…Œì´ë¸”ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    
    def test_pptx_detailed_parsing(self):
        """PPTX ìƒì„¸ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = PptxParser()
        pptx_file = PRIVATE_DIR / "test_presentation.pptx"
        
        if not pptx_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pptx_file}")
        
        print(f"\n{'='*60}")
        print(f"PPTX íŒŒì‹± ì‹œì‘: {pptx_file.name}")
        print(f"{'='*60}\n")
        
        doc = parser.parse(pptx_file)
        
        # ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"ë©”íƒ€ë°ì´í„°:")
        print(f"  - ì œëª©: {doc.metadata.title}")
        print(f"  - ìŠ¬ë¼ì´ë“œ ìˆ˜: {doc.metadata.page_count}")
        print(f"\ní†µê³„:")
        print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
        print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
        print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
        print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
        
        # ìŠ¬ë¼ì´ë“œë³„ ì œëª© ì¶œë ¥
        headings = [tc for tc in doc.text_contents if tc.level > 0]
        if headings:
            print(f"\nìŠ¬ë¼ì´ë“œ ì œëª©:")
            for heading in headings:
                print(f"  - [ìŠ¬ë¼ì´ë“œ {heading.page_number}] {heading.text}")
        
        # í…Œì´ë¸” ë¯¸ë¦¬ë³´ê¸°
        if doc.tables:
            print(f"\ní…Œì´ë¸” ì •ë³´:")
            for i, table in enumerate(doc.tables, 1):
                print(f"  í…Œì´ë¸” {i} (ìŠ¬ë¼ì´ë“œ {table.page_number}): {len(table.headers)} x {len(table.rows)}")
        
        # ë§ˆí¬ë‹¤ìš´ ì €ì¥
        folder_name = "pptx_test"
        md_path = save_parsing_result_to_markdown(doc, folder_name)
        print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
        
        assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert len(headings) > 0, "ì œëª©ì´ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert doc.metadata.page_count > 0, "ìŠ¬ë¼ì´ë“œ ìˆ˜ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤"
    
    def test_real_pptx_file1(self):
        """ì‹¤ì œ PPTX íŒŒì¼ 1 íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = PptxParser()
        pptx_file = PRIVATE_DIR / "PPTìƒ˜í”Œ_20201027.pptx"
        
        if not pptx_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pptx_file}")
        
        print(f"\n{'='*60}")
        print(f"ì‹¤ì œ PPTX íŒŒì¼ 1 íŒŒì‹± ì‹œì‘: {pptx_file.name[:50]}...")
        print(f"{'='*60}\n")
        
        try:
            doc = parser.parse(pptx_file)
            
            # ìƒì„¸ ì •ë³´ ì¶œë ¥
            print(f"ë©”íƒ€ë°ì´í„°:")
            print(f"  - ì œëª©: {doc.metadata.title}")
            print(f"  - ìŠ¬ë¼ì´ë“œ ìˆ˜: {doc.metadata.page_count}")
            print(f"\ní†µê³„:")
            print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
            print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
            print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
            print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
            
            # ì²˜ìŒ 5ê°œ ìŠ¬ë¼ì´ë“œ ì œëª©
            headings = [tc for tc in doc.text_contents if tc.level > 0]
            if headings:
                print(f"\nì²˜ìŒ 5ê°œ ìŠ¬ë¼ì´ë“œ ì œëª©:")
                for heading in headings[:5]:
                    print(f"  - [ìŠ¬ë¼ì´ë“œ {heading.page_number}] {heading.text[:80]}")
            
            # ë§ˆí¬ë‹¤ìš´ ì €ì¥
            folder_name = "pptx_novaplex_eu"
            md_path = save_parsing_result_to_markdown(doc, folder_name)
            print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
            
            assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            assert doc.metadata.page_count > 0, "ìŠ¬ë¼ì´ë“œ ìˆ˜ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤"
        except Exception as e:
            print(f"\nâŒ íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise
    
    def test_real_pptx_file2(self):
        """ì‹¤ì œ PPTX íŒŒì¼ 2 íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = PptxParser()
        pptx_file = PRIVATE_DIR / "PPTìƒ˜í”Œ_ê°œë°œ.pptx"
        
        if not pptx_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pptx_file}")
        
        print(f"\n{'='*60}")
        print(f"ì‹¤ì œ PPTX íŒŒì¼ 2 íŒŒì‹± ì‹œì‘: {pptx_file.name[:50]}...")
        print(f"{'='*60}\n")
        
        try:
            doc = parser.parse(pptx_file)
            
            # ìƒì„¸ ì •ë³´ ì¶œë ¥
            print(f"ë©”íƒ€ë°ì´í„°:")
            print(f"  - ì œëª©: {doc.metadata.title}")
            print(f"  - ìŠ¬ë¼ì´ë“œ ìˆ˜: {doc.metadata.page_count}")
            print(f"\ní†µê³„:")
            print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
            print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
            print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
            print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
            
            # ì²˜ìŒ 5ê°œ ìŠ¬ë¼ì´ë“œ ì œëª©
            headings = [tc for tc in doc.text_contents if tc.level > 0]
            if headings:
                print(f"\nì²˜ìŒ 5ê°œ ìŠ¬ë¼ì´ë“œ ì œëª©:")
                for heading in headings[:5]:
                    print(f"  - [ìŠ¬ë¼ì´ë“œ {heading.page_number}] {heading.text[:80]}")
            
            # ë§ˆí¬ë‹¤ìš´ ì €ì¥
            folder_name = "pptx_tick_borne_expanded"
            md_path = save_parsing_result_to_markdown(doc, folder_name)
            print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
            
            assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            assert doc.metadata.page_count > 0, "ìŠ¬ë¼ì´ë“œ ìˆ˜ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤"
        except Exception as e:
            print(f"\nâŒ íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise
    
    def test_real_docx_file(self):
        """ì‹¤ì œ DOCX íŒŒì¼ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        parser = DocxParser()
        docx_file = PRIVATE_DIR / "[PPTë³€í™˜ ìƒ˜í”Œ].docx"
        
        if not docx_file.exists():
            pytest.skip(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {docx_file}")
        
        print(f"\n{'='*60}")
        print(f"ì‹¤ì œ DOCX íŒŒì¼ íŒŒì‹± ì‹œì‘: {docx_file.name[:50]}...")
        print(f"{'='*60}\n")
        
        try:
            doc = parser.parse(docx_file)
            
            # ìƒì„¸ ì •ë³´ ì¶œë ¥
            print(f"ë©”íƒ€ë°ì´í„°:")
            print(f"  - ì œëª©: {doc.metadata.title}")
            print(f"  - í˜ì´ì§€ ìˆ˜: {doc.metadata.page_count}")
            print(f"\ní†µê³„:")
            print(f"  - í…ìŠ¤íŠ¸ ë¸”ë¡: {len(doc.text_contents)}ê°œ")
            print(f"  - ì œëª©: {len([tc for tc in doc.text_contents if tc.level > 0])}ê°œ")
            print(f"  - í…Œì´ë¸”: {len(doc.tables)}ê°œ")
            print(f"  - ì´ë¯¸ì§€: {len(doc.images)}ê°œ")
            print(f"  - ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(doc.full_text)} ë¬¸ì")
            
            # ì²˜ìŒ 5ê°œ ì œëª©
            headings = [tc for tc in doc.text_contents if tc.level > 0]
            if headings:
                print(f"\nì²˜ìŒ 5ê°œ ì œëª©:")
                for heading in headings[:5]:
                    print(f"  - [ë ˆë²¨ {heading.level}] {heading.text[:80]}")
            
            # ë§ˆí¬ë‹¤ìš´ ì €ì¥
            folder_name = "docx_tick_borne"
            md_path = save_parsing_result_to_markdown(doc, folder_name)
            print(f"\nâœ… ê²°ê³¼ ì €ì¥: {md_path}")
            
            assert len(doc.text_contents) > 0, "í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        except Exception as e:
            print(f"\nâŒ íŒŒì‹± ì‹¤íŒ¨: {e}")
            raise
